{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nu3T06eqa1fN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. What is Simple Linear Regression?  \n",
        "Simple Linear Regression is a method to predict the dependent variable (Y) using one independent variable (X) by fitting a straight line.\n",
        "\n",
        "2. What are the key assumptions of Simple Linear Regression?  \n",
        "Linearity, independence, homoscedasticity, and normality of residuals.\n",
        "\n",
        "3. What does the coefficient m represent in the equation Y=mx+c?  \n",
        "It represents the slope or rate of change of Y with respect to X.\n",
        "\n",
        "4. What does the intercept c represent in the equation Y=mx+c?  \n",
        "It is the value of Y when X is 0, indicating where the line crosses the Y-axis.\n",
        "\n",
        "5. How do we calculate the slope m in Simple Linear Regression?  \n",
        "m = Σ[(X - X̄)(Y - Ȳ)] / Σ[(X - X̄)²]\n",
        "\n",
        "6. What is the purpose of the least squares method in Simple Linear Regression?  \n",
        "To minimize the sum of the squared differences between actual and predicted Y values.\n",
        "\n",
        "7. How is the coefficient of determination (R²) interpreted in Simple Linear Regression?  \n",
        "It shows how much variance in Y is explained by X; ranges from 0 to 1.\n",
        "\n",
        "8. What is Multiple Linear Regression?  \n",
        "It’s a regression technique where Y is predicted using two or more independent variables.\n",
        "\n",
        "9. What is the main difference between Simple and Multiple Linear Regression?  \n",
        "Simple uses one independent variable; multiple uses more than one.\n",
        "\n",
        "10. What are the key assumptions of Multiple Linear Regression?  \n",
        "Linearity, multivariate normality, no multicollinearity, and homoscedasticity.\n",
        "\n",
        "11. What is heteroscedasticity, and how does it affect the results of a Multiple Linear Regression model?  \n",
        "It means unequal variance of errors; it can lead to inefficient and biased estimates.\n",
        "\n",
        "12. How can you improve a Multiple Linear Regression model with high multicollinearity?  \n",
        "By removing or combining correlated predictors, or using regularization techniques like Ridge/Lasso.\n",
        "\n",
        "13. What are some common techniques for transforming categorical variables for use in regression models?  \n",
        "One-hot encoding and label encoding.\n",
        "\n",
        "14. What is the role of interaction terms in Multiple Linear Regression?  \n",
        "They help model the combined effect of two variables on the dependent variable.\n",
        "\n",
        "15. How can the interpretation of intercept differ between Simple and Multiple Linear Regression?  \n",
        "In multiple regression, the intercept is the predicted Y when all Xs are zero, which may not be meaningful.\n",
        "\n",
        "16. What is the significance of the slope in regression analysis, and how does it affect predictions?  \n",
        "It shows how much Y changes with a unit change in X; steeper slope = stronger relationship.\n",
        "\n",
        "17. How does the intercept in a regression model provide context for the relationship between variables?  \n",
        "It anchors the regression line and helps interpret Y when all Xs are zero.\n",
        "\n",
        "18. What are the limitations of using R² as a sole measure of model performance?  \n",
        "It doesn’t reflect model bias, overfitting, or how well the model will perform on new data.\n",
        "\n",
        "19. How would you interpret a large standard error for a regression coefficient?  \n",
        "It indicates that the estimate of the coefficient is unstable and uncertain.\n",
        "\n",
        "20. How can heteroscedasticity be identified in residual plots, and why is it important to address it?  \n",
        "By observing fan-shaped residuals; it's important because it violates regression assumptions.\n",
        "\n",
        "21. What does it mean if a Multiple Linear Regression model has a high R² but low adjusted R²?  \n",
        "It suggests overfitting due to too many irrelevant predictors.\n",
        "\n",
        "22. Why is it important to scale variables in Multiple Linear Regression?  \n",
        "To ensure fair comparison and avoid dominance of variables with larger scales.\n",
        "\n",
        "23. What is polynomial regression?  \n",
        "A regression technique that models the relationship as an nth degree polynomial.\n",
        "\n",
        "24. How does polynomial regression differ from linear regression?  \n",
        "It fits curves (nonlinear) instead of straight lines to the data.\n",
        "\n",
        "25. When is polynomial regression used?  \n",
        "When the relationship between variables is nonlinear.\n",
        "\n",
        "26. What is the general equation for polynomial regression?  \n",
        "Y = β₀ + β₁X + β₂X² + ... + βnXⁿ + ε\n",
        "\n",
        "27. Can polynomial regression be applied to multiple variables?  \n",
        "Yes, it can be extended to multiple variables using polynomial terms of each.\n",
        "\n",
        "28. What are the limitations of polynomial regression?  \n",
        "It may overfit, be sensitive to outliers, and can become computationally complex.\n",
        "\n",
        "29. What methods can be used to evaluate model fit when selecting the degree of a polynomial?  \n",
        "Cross-validation, adjusted R², and AIC/BIC.\n",
        "\n",
        "30. Why is visualization important in polynomial regression?  \n",
        "To understand model fit, check for overfitting, and interpret relationships better.\n",
        "\n",
        "31. How is polynomial regression implemented in Python?  \n",
        "Using `PolynomialFeatures` from sklearn to transform X, then applying `LinearRegression`.\n"
      ],
      "metadata": {
        "id": "vtZ2xkVLa7kw"
      }
    }
  ]
}